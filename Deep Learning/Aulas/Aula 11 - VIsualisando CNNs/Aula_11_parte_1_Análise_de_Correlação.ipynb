{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Análise de Correlação"
      ],
      "metadata": {
        "id": "5vd9n1GnAZRT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxwcTN6Z0Fq5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount._DEBUG = False\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "OGWuiky0A-27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_dim = 64\n",
        "\n",
        "def create_fixed_permutation(shape, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    indices = np.arange(np.prod(shape))\n",
        "    np.random.shuffle(indices)\n",
        "    return indices.reshape(shape).flatten()\n",
        "\n",
        "def apply_permutation(image, permutation):\n",
        "    arr = np.array(image)\n",
        "    flat_arr = arr.flatten()\n",
        "    shuffled_arr = flat_arr[permutation]\n",
        "    return Image.fromarray(shuffled_arr.reshape(arr.shape))\n",
        "\n",
        "def process_images_with_fixed_permutation(root_dir, seed=42):\n",
        "    \"\"\"\n",
        "    Processa todas as imagens em um diretório, embaralhando os pixels\n",
        "    de acordo com uma permutação fixa.\n",
        "    \"\"\"\n",
        "    first_image_path = None\n",
        "    target_size = (img_dim, img_dim)\n",
        "    processadas = 0\n",
        "\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            try:\n",
        "                with Image.open(file_path) as img:\n",
        "                    img = img.convert('L')  # L para grayscale\n",
        "                    img = img.resize(target_size, Image.LANCZOS)\n",
        "                    if first_image_path is None:\n",
        "                        first_image_path = file_path\n",
        "                        permutation = create_fixed_permutation(np.array(img).shape, seed)\n",
        "\n",
        "                    shuffled_img = apply_permutation(img, permutation)\n",
        "                    # Salvar remapeamento\n",
        "                    shuffled_img.save(file_path)\n",
        "                    processadas += 1\n",
        "                    if processadas % 10000 == 0:\n",
        "                        print(f\"Processadas {processadas} imagens\")\n",
        "            except Exception as e:\n",
        "                print(f\"Falha ao processar {file_path}: {e}\")"
      ],
      "metadata": {
        "id": "JT14xWlAqtxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKWRPl0L0Q8G"
      },
      "outputs": [],
      "source": [
        "#Carregue os dados PKLotSegmented.tar.gz para seu Google Drive antes de executar\n",
        "#Ajuste o path para apontar para o local do arquivo\n",
        "\n",
        "!rm -rf /content/datasets\n",
        "!mkdir /content/datasets\n",
        "!rm -rf /content/datasets_shuffle\n",
        "!mkdir /content/datasets_shuffle\n",
        "\n",
        "!tar -xf \"/content/drive/MyDrive/PKLotSegmented.tar.gz\" -C \"/content/datasets\"\n",
        "#Ou, se o .tar.gz já estiver carregado no seu ambiente:\n",
        "!tar -xf \"/content/PKLotSegmented.tar.gz\" -C \"/content/datasets\"\n",
        "\n",
        "!mv /content/datasets/Treino-UFPR04 /content/datasets/treino\n",
        "!mv /content/datasets/Validação-UFPR05 /content/datasets/validacao\n",
        "!mv /content/datasets/Teste-PUC /content/datasets/teste\n",
        "\n",
        "!cp -r /content/datasets/ /content/datasets_shuffle\n",
        "\n",
        "!mv /content/datasets_shuffle/datasets/* /content/datasets_shuffle/\n",
        "!rm -r /content/datasets_shuffle/datasets/\n",
        "\n",
        "process_images_with_fixed_permutation('/content/datasets_shuffle/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ver as imagens com shuffle de pixels\n",
        "from IPython.display import Image as image_display\n",
        "from IPython.display import display\n",
        "\n",
        "display(image_display('/content/datasets/treino/Occupied/2012-12-07_16_42_25#001.jpg'))\n",
        "display(image_display('/content/datasets_shuffle/treino/Occupied/2012-12-07_16_42_25#001.jpg'))"
      ],
      "metadata": {
        "id": "0QptFbK_rmta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWYUk8JAxi9H"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OklY8Sj_0aRC"
      },
      "outputs": [],
      "source": [
        "# Dataloaders\n",
        "\n",
        "\n",
        "#ATENÇÃO: Execute primeiro os experimentos com /content/datasets\n",
        "# Depois, entenda como são as imagens no diretório /content/datasets/shuffle, e então execute os experimentos usando esse diretório\n",
        "data_dir = \"/content/datasets\"\n",
        "#data_dir = \"/content/datasets_shuffle\"\n",
        "\n",
        "#As imagens tratadas serão em escala de cinza para diminuir o tamanho das redes\n",
        "data_transforms = {\n",
        "    \"treino\": transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    \"validacao\": transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "    \"teste\": transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((img_dim, img_dim)),\n",
        "        transforms.ToTensor()\n",
        "    ]),\n",
        "}\n",
        "\n",
        "sets = [\"treino\", \"validacao\", \"teste\"]\n",
        "\n",
        "print(\"Criando dataloaders para diretório\", data_dir)\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(root=f'{data_dir}/{x}', transform=data_transforms[x])\n",
        "                  for x in sets}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=2)\n",
        "               for x in sets}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in sets}\n",
        "class_names = image_datasets['treino'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Conectado em um ambiente com\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCULctyHx43T"
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (1, img_dim, img_dim)\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "#Definição de uma CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=INPUT_SHAPE[0], out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 64)\n",
        "        self.fc2 = nn.Linear(64, NUM_CLASSES)\n",
        "\n",
        "    def convs(self, x):\n",
        "        x = f.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = f.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = f.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x = self.flatten(x)\n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "#Definição de um MLP convencional de 3 camadas ocultas\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
        "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
        "        self.fc3 = nn.Linear(hidden_sizes[1], hidden_sizes[2])\n",
        "        self.fc4 = nn.Linear(hidden_sizes[2], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout_input = nn.Dropout(0.1)\n",
        "        self.dropout_hidden = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout_input(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout_hidden(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout_hidden(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.dropout_hidden(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBgt5eam0Eqh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQDWc4jjyKXQ"
      },
      "outputs": [],
      "source": [
        "# Função para treinar o modelo\n",
        "def train_model(model, criterion, optimizer, epochs=3):\n",
        "    best_loss = math.inf\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Época {epoch+1}/{epochs}\")\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in [\"treino\", \"validacao\"]:\n",
        "            if phase == \"treino\":\n",
        "                model.train()  # Colocar o modelo em modo de treino\n",
        "            else:\n",
        "                model.eval()   # Colocar o modelo em modo de avaliação\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == \"treino\"):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == \"treino\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcaXtMFO1BST"
      },
      "outputs": [],
      "source": [
        "print(\"Testes para CNN\")\n",
        "\n",
        "#Treinamento\n",
        "#model_cnn = CNN()\n",
        "\n",
        "model_cnn = models.mobilenet_v3_small(pretrained=True)\n",
        "\n",
        "model_cnn.features[0][0] = nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "model_cnn.classifier[3] = nn.Linear(model_cnn.classifier[3].in_features, 2)\n",
        "\n",
        "for param in model_cnn.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model_cnn = model_cnn.to(device)\n",
        "\n",
        "# Função de loss e o otimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.002)\n",
        "optimizer_cnn = optim.SGD(model_cnn.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# Treinar o modelo\n",
        "print(\"Treinando\")\n",
        "train_model(model_cnn, criterion, optimizer_cnn, epochs=5)\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "print(\"Avaliando CNN no conjunto de testes\")\n",
        "model_cnn.eval()\n",
        "test_corrects = 0\n",
        "\n",
        "for inputs, labels in dataloaders['teste']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model_cnn(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = test_corrects.double() / dataset_sizes['teste']\n",
        "print(f'Test Acc: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "print(\"Testes para MLP\")\n",
        "\n",
        "input_size = img_dim * img_dim\n",
        "hidden_sizes = [512, 256, 128]\n",
        "output_size = len(class_names)\n",
        "\n",
        "model_mlp = MLP(input_size, hidden_sizes, output_size)\n",
        "model_mlp = model_mlp.to(device)\n",
        "\n",
        "# otimizador\n",
        "#optimizer_mlp = optim.Adam(model_mlp.parameters(), lr=0.001)\n",
        "optimizer_mlp = optim.SGD(model_mlp.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "# Treinar o modelo\n",
        "print(\"Treinando\")\n",
        "train_model(model_mlp, criterion, optimizer_mlp, epochs=5)\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "print(\"Avaliando MLP no conjunto de testes\")\n",
        "model_mlp.eval()\n",
        "test_corrects = 0\n",
        "\n",
        "for inputs, labels in dataloaders['teste']:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model_mlp(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = test_corrects.double() / dataset_sizes['teste']\n",
        "print(f'Test Acc: {test_acc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cnD4qXekY38i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}