{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn5zVXM9kiCb"
      },
      "source": [
        "# Exercícios Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WkhvOYpErxBs"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercicio1\n",
        "\n",
        "Considere que w é inicializado aleatoriamente, e que o problema em questão é linearmente separável. Executamos o algoritmo do perceptron duas vezes para o mesmo conjunto de treinamento. É possível que:\n",
        "\n",
        "* a: O número de épocas necessárias para convergir para a solução seja diferente entre as duas execuções?\n",
        "* b: A fronteira (valor final de w) seja diferente entre as duas execuções?\n",
        "\n",
        "### Respostas\n",
        "\n",
        "* a: Sim, o numero de epocas pode ser diferente. Isso ocorre pelo fato das diferencas dos valores inicias de W. Em um caso, podemos comecar com um vetor de pesos inicias mais proximo do \"otimo\" antes.\n",
        "* b: Sim, pesos inicias diferentes podem gerar fronteiras diferentes, visando que o algoritmo para a partir do primeiro momento que classifica todas as classes corretamente ou atinge o limite de epocas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercicio 3\n",
        "\n",
        "Modifique o problema do exemplo Iris Setosa para manter todas as quatro características do problema original, mas mantenha só as duas primeiras classes, como feito em aula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Eb9lV4u7_kAQ",
        "outputId": "0da5f97a-c7b4-4784-c72d-aebdc74944be"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df[\"target\"] = iris.target\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "iris_df[iris.feature_names] = scaler.fit_transform(iris_df[iris.feature_names])\n",
        "\n",
        "vectors_class_0 = iris_df[iris_df[\"target\"] == 0]\n",
        "vectors_class_1 = iris_df[iris_df[\"target\"] == 1]\n",
        "\n",
        "\n",
        "vectors_class_0[\"target\"] = - 1\n",
        "vectors_class_1[\"target\"] = + 1\n",
        "\n",
        "vectors = np.concatenate((vectors_class_0.to_numpy(), vectors_class_1.to_numpy()))\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(vectors) \n",
        "\n",
        "w =  np.array([1.0, 1.0, 1.0, 1.0, -1.0])\n",
        "eta = 1\n",
        "\n",
        "allOk = False\n",
        "count, epochs = 0, 15\n",
        "while count < epochs and not allOk:\n",
        "    print(f\"Epoca: {count + 1}\")\n",
        "\n",
        "    allOk = True\n",
        "    for x in vectors:\n",
        "        bias_input = np.array([1, x[0], x[1], x[2], x[3]])\n",
        "        result = w.dot(bias_input)\n",
        "        result = 1 if result >= 0 else -1\n",
        "\n",
        "        if result != x[4]:\n",
        "            w += (eta * x[4] * bias_input)\n",
        "            allOk = False\n",
        "\n",
        "    count += 1\n",
        "\n",
        "print(f\"Epocas necessarias: {count}\")\n",
        "print(\"Resultado final: \")\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercicio 4\n",
        "\n",
        "Modifique o problema Iris Setosa agora para considerar todas as quatro características e três classes. Como usar múltiplos perceptrons em um pipeline para gerar fronteiras nesse problema multiclasse?\n",
        "\n",
        "### Ideia\n",
        "\n",
        "Um caminho possivel seria criar uma pipeline com 2 perceptrons, o primeiro responsavel por identificar uma unica classe, e o segundo para identificar as duas classes restantes. Dessa forma, primeiro seria executado o processo no perceptron 1, e caso ele nao apontasse como o resultado sendo a classe em questao, o mesmo input seria executado no perceptron 2.\n",
        "\n",
        "As duvidas desse processo sao basicamente como treinar o primeiro modelo para apenas uma classe. Como nao temos camadas conectadas, neste caso nao seria necessario o processo de backpropagation para o treinamento, cada perceptron seria treinado isoladamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class perceptron():\n",
        "    def __init__(self):\n",
        "        self.w = [1.0, 1.0, 1.0, 1.0]\n",
        "    \n",
        "\n",
        "    # Remove the target from the vector, otherwise this will fail\n",
        "    def fit(self, vectors, epochs):\n",
        "        allOk, count = False, 0\n",
        "\n",
        "        while count < epochs and not allOk:\n",
        "            allOk = True\n",
        "            for x in vectors:\n",
        "                bias_input = np.append(1, x)\n",
        "                result = w.dot(bias_input)\n",
        "                result = 1 if result >= 0 else -1\n",
        "\n",
        "                if result != x[4]:\n",
        "                    self.w += (eta * x[4] * bias_input)\n",
        "                    allOk = False\n",
        "\n",
        "            count += 1\n",
        "\n",
        "\n",
        "    # Remove the target from the vector, otherwise this will fail\n",
        "    # Return one preds vector with values +1 and -1, need to adapt the result for the pipeline\n",
        "    def predict(self, vectors):\n",
        "        preds = []\n",
        "\n",
        "        for x in vectors:\n",
        "            bias_input = np.append(1, x)\n",
        "            result = w.dot(bias_input)\n",
        "            preds.append(1 if result >= 0 else -1)\n",
        "\n",
        "        return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df[\"target\"] = iris.target\n",
        "\n",
        "first_perc_df = iris_df[~iris_df['target'].isin([1, 2])]\n",
        "second_perc_df = iris_df[~iris_df['target'].isin([0])]\n",
        "\n",
        "# Train the first perceptron with the fisrt_perc_df\n",
        "# Train the second perceptron with the second_perc_df\n",
        "# Create an pipeline using both perceptrons.\n",
        "#   If the result from the first perceptron was not 1, it means that its not class 0\n",
        "#   So its need to run in the second perceptron.\n",
        "#   +1 in the second perceptron means class 1 and -1 means class 2.\n",
        "#   The ideia is basicaly create 2 frontiers, one dividing the class 0 from the other 2\n",
        "#   ANd the second one dividing the last 2 classes"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W9OofqLhlPrF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
