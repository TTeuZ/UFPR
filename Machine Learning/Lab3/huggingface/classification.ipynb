{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../Files/imdb_master.csv\"\n",
    "aux = {\"neg\": 0, \"pos\": 1}\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open(data, encoding=\"ISO-8859-1\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if not (row['label'] == \"unsup\"):\n",
    "            texts.append(row['review'])\n",
    "            labels.append(aux[row['label']])\n",
    "\n",
    "texts = texts[int(len(texts) / 2) :]\n",
    "labels = labels[int(len(labels) / 2) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_data(texts):\n",
    "    for text in texts:\n",
    "        yield text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = ['siebert/sentiment-roberta-large-english',\n",
    "               'bhadresh-savani/distilbert-base-uncased-sentiment-sst2',\n",
    "               'cardiffnlp/twitter-roberta-base-sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at siebert/sentiment-roberta-large-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at bhadresh-savani/distilbert-base-uncased-sentiment-sst2 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-sentiment-sst2 and are newly initialized: ['dropout_93']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_preds = {}\n",
    "\n",
    "for model_path in model_paths:\n",
    "    model = pipeline(\"sentiment-analysis\", model=model_path, tokenizer=model_path, max_length=512, truncation=True, batch_size=500)\n",
    "\n",
    "    preds = []\n",
    "    for pred in model(yield_data(texts)):\n",
    "        preds.append(pred)\n",
    "    \n",
    "    model_preds[model_path] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['siebert/sentiment-roberta-large-english', 'bhadresh-savani/distilbert-base-uncased-sentiment-sst2', 'cardiffnlp/twitter-roberta-base-sentiment'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11820   680]\n",
      " [  603 11897]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     12500\n",
      "           1       0.95      0.95      0.95     12500\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.95      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_aux = {'NEGATIVE': 0, 'POSITIVE': 1, 'NEUTRAL': 1}\n",
    "\n",
    "model_pred = model_preds['siebert/sentiment-roberta-large-english']\n",
    "processed_pred = [label_aux[pred['label']] for pred in model_pred];\n",
    "\n",
    "print(confusion_matrix(labels, processed_pred))\n",
    "print(classification_report(labels, processed_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11387  1113]\n",
      " [ 1953 10547]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     12500\n",
      "           1       0.90      0.84      0.87     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_aux = {'NEGATIVE': 0, 'POSITIVE': 1}\n",
    "\n",
    "model_pred = model_preds['bhadresh-savani/distilbert-base-uncased-sentiment-sst2']\n",
    "processed_pred = [label_aux[pred['label']] for pred in model_pred];\n",
    "\n",
    "print(confusion_matrix(labels, processed_pred))\n",
    "print(classification_report(labels, processed_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9884  2616]\n",
      " [  913 11587]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85     12500\n",
      "           1       0.82      0.93      0.87     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.87      0.86      0.86     25000\n",
      "weighted avg       0.87      0.86      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_aux = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 1}\n",
    "\n",
    "model_pred = model_preds['cardiffnlp/twitter-roberta-base-sentiment']\n",
    "processed_pred = [label_aux[pred['label']] for pred in model_pred];\n",
    "\n",
    "print(confusion_matrix(labels, processed_pred))\n",
    "print(classification_report(labels, processed_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aux = {'NEGATIVE': 0, 'POSITIVE': 1, 'NEUTRAL': 1}\n",
    "label_aux2 = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 1}\n",
    "\n",
    "processed_preds = {}\n",
    "\n",
    "model_pred = model_preds['siebert/sentiment-roberta-large-english']\n",
    "processed_preds['siebert/sentiment-roberta-large-english'] = [(label_aux[pred['label']], pred['score']) for pred in model_pred];\n",
    "\n",
    "model_pred = model_preds['bhadresh-savani/distilbert-base-uncased-sentiment-sst2']\n",
    "processed_preds['bhadresh-savani/distilbert-base-uncased-sentiment-sst2'] = [(label_aux[pred['label']], pred['score']) for pred in model_pred];\n",
    "\n",
    "model_pred = model_preds['cardiffnlp/twitter-roberta-base-sentiment']\n",
    "processed_preds['cardiffnlp/twitter-roberta-base-sentiment'] = [(label_aux2[pred['label']], pred['score']) for pred in model_pred];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11768   732]\n",
      " [  896 11604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     12500\n",
      "           1       0.94      0.93      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metodo da soma\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_porcentage = 0\n",
    "    negative_porcentage = 0\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_porcentage += processed_preds[pred][index][1]\n",
    "            negative_porcentage += 1 - processed_preds[pred][index][1]\n",
    "        else:\n",
    "            positive_porcentage += 1 - processed_preds[pred][index][1]\n",
    "            negative_porcentage += processed_preds[pred][index][1]\n",
    "\n",
    "    if positive_porcentage > negative_porcentage:\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11835   665]\n",
      " [  650 11850]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     12500\n",
      "           1       0.95      0.95      0.95     12500\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.95      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metodo do produto\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_porcentage = 1\n",
    "    negative_porcentage = 1\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_porcentage = positive_porcentage * processed_preds[pred][index][1]\n",
    "            negative_porcentage = negative_porcentage * (1 - processed_preds[pred][index][1])\n",
    "        else:\n",
    "            positive_porcentage = positive_porcentage * (1 - processed_preds[pred][index][1])\n",
    "            negative_porcentage = negative_porcentage * processed_preds[pred][index][1]\n",
    "\n",
    "    if positive_porcentage > negative_porcentage:\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11768   732]\n",
      " [  896 11604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94     12500\n",
      "           1       0.94      0.93      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metodo da media\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_porcentage = 0\n",
    "    negative_porcentage = 0\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_porcentage += processed_preds[pred][index][1]\n",
    "            negative_porcentage += (1 - processed_preds[pred][index][1])\n",
    "        else:\n",
    "            positive_porcentage += (1 - processed_preds[pred][index][1])\n",
    "            negative_porcentage += processed_preds[pred][index][1]\n",
    "\n",
    "    if (positive_porcentage / 3) > (negative_porcentage / 3):\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11842   658]\n",
      " [  636 11864]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     12500\n",
      "           1       0.95      0.95      0.95     12500\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.95      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regra do minimo\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_porcentage = []\n",
    "    negative_porcentage = []\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_porcentage.append(processed_preds[pred][index][1])\n",
    "            negative_porcentage.append((1 - processed_preds[pred][index][1]))\n",
    "        else:\n",
    "            positive_porcentage.append((1 - processed_preds[pred][index][1]))\n",
    "            negative_porcentage.append(processed_preds[pred][index][1])\n",
    "\n",
    "    if min(positive_porcentage) > min(negative_porcentage):\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11842   658]\n",
      " [  636 11864]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     12500\n",
      "           1       0.95      0.95      0.95     12500\n",
      "\n",
      "    accuracy                           0.95     25000\n",
      "   macro avg       0.95      0.95      0.95     25000\n",
      "weighted avg       0.95      0.95      0.95     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Regra do maximo\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_porcentage = []\n",
    "    negative_porcentage = []\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_porcentage.append(processed_preds[pred][index][1])\n",
    "            negative_porcentage.append((1 - processed_preds[pred][index][1]))\n",
    "        else:\n",
    "            positive_porcentage.append((1 - processed_preds[pred][index][1]))\n",
    "            negative_porcentage.append(processed_preds[pred][index][1])\n",
    "\n",
    "    if max(positive_porcentage) > max(negative_porcentage):\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11431  1069]\n",
      " [  801 11699]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     12500\n",
      "           1       0.92      0.94      0.93     12500\n",
      "\n",
      "    accuracy                           0.93     25000\n",
      "   macro avg       0.93      0.93      0.93     25000\n",
      "weighted avg       0.93      0.93      0.93     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando voto majoritario\n",
    "\n",
    "final_result = []\n",
    "for index in range(len(labels)):\n",
    "    positive_votes = 0\n",
    "    negative_votes = 0\n",
    "    for pred in processed_preds:\n",
    "        if processed_preds[pred][index][0] == 1:\n",
    "            positive_votes += 1\n",
    "        else:\n",
    "            negative_votes += 1\n",
    "\n",
    "    if positive_votes > negative_votes:\n",
    "        final_result.append(1)\n",
    "    else:\n",
    "        final_result.append(0)\n",
    "\n",
    "print(confusion_matrix(labels, final_result))\n",
    "print(classification_report(labels, final_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
