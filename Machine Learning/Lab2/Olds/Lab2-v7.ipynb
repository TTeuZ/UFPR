{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YwNAuSHMZNKVTmglOzOW0-Lrqx00DCW_","authorship_tag":"ABX9TyMCUDAQi6irU7NIljfduUmA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kjzztfGwe1XX"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","!pip install smogn\n","import smogn\n","\n","from sklearn.impute import KNNImputer\n","from sklearn import neighbors\n","from sklearn import linear_model\n","from sklearn import svm\n","from sklearn import tree\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"markdown","source":["### 1° Leitura e tratamento inicial dos dados\n","\n","Lendo a CSV e removendo todos os dados com valores de Tp_est iguais a zero. Além disso, foi realizado o tratamento inicial e construção das 3 bases de dados usados no algoritmo\n","\n","Resultados:\n","- Base de dados raw para treinamento (*df_raw_train*)\n","- Base de dados raw para validação (*df_raw_validation*)\n","- Base de dados raw para teste (*df_raw_test*)"],"metadata":{"id":"Dp3ndF8DfZRl"}},{"cell_type":"code","source":["df_raw_data = pd.read_csv('/content/drive/MyDrive/BCC - UFPR/Semestres /9 - 2023-2/Aprendizado de Maquina/Lab2/Dados_Radar_Estacao_Completo_2018_2022.csv')\n","df_raw_data.drop(df_raw_data[df_raw_data['Tp_est'] == 0.0].index, inplace=True);"],"metadata":{"id":"apl-nNRqfdxS","executionInfo":{"status":"ok","timestamp":1696727418977,"user_tz":180,"elapsed":20282,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Remoção de colunas da base geral (2018 a 2022). A colunas removidas foram:\n","- Unnamed: 0 pois é a coluna de ids\n","- latitude e longitude pois possuem a mesma informação que as colunas lat e lon;\n","- distancia pois não agrega valor ao modelo.\n"],"metadata":{"id":"ZfVDhdkUffjS"}},{"cell_type":"code","source":["df_raw_data.drop(['Unnamed: 0', 'latitude', 'longitude', 'distancia'], axis=1, inplace=True)"],"metadata":{"id":"VDVwGtoxXAJ-","executionInfo":{"status":"ok","timestamp":1696727418977,"user_tz":180,"elapsed":3,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Separando o raw data entre treinamento e teste. Anos de 2018 a 2021 para treinamento e 2022 para teste.\n"],"metadata":{"id":"niHUe8qRfkJ1"}},{"cell_type":"code","source":["raw_train_test_group = df_raw_data.groupby(df_raw_data['time'].str.contains('2022'))\n","\n","df_raw_train = raw_train_test_group.get_group(False).copy()\n","df_raw_test = raw_train_test_group.get_group(True).copy()"],"metadata":{"id":"bpE1520yfk37","executionInfo":{"status":"ok","timestamp":1696727418977,"user_tz":180,"elapsed":2,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Separando os dados de treinamento, selecionando uma porção dos dados para validação"],"metadata":{"id":"GoFReL0bEj1I"}},{"cell_type":"code","source":["dates = ['2018-01', '2018-02']\n","\n","raw_train_validation_group = df_raw_train.groupby(df_raw_train['time'].str.contains('|'.join(dates)))\n","df_raw_train = raw_train_validation_group.get_group(False).copy()\n","df_raw_validation = raw_train_validation_group.get_group(True).copy()\n"],"metadata":{"id":"bcSHW_v-foR1","executionInfo":{"status":"ok","timestamp":1696727419357,"user_tz":180,"elapsed":382,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Remoção das colunas elevation e sweep pois não possuiam valor agregado na base\n","\n","Para verificar que as colunas elevation e sweep não possuiam valor agregado, foi utilizado a função describe do pandas. Com esta função, foi possível verificar que ambas possuiam média, minimo e maximo identicos, além de um desvio padrão igual a 0, ou seja, todas as linhas possuiam o mesmo valor."],"metadata":{"id":"x2L_kDfHfqD-"}},{"cell_type":"code","source":["print(df_raw_train.describe()['elevation'], end=\"\\n\\n\")\n","print(df_raw_train.describe()['sweep'])\n","\n","df_raw_train.drop(['elevation', 'sweep'], axis=1, inplace=True)\n","df_raw_validation.drop(['elevation', 'sweep'], axis=1, inplace=True)\n","df_raw_test.drop(['elevation', 'sweep'], axis=1, inplace=True)"],"metadata":{"id":"8pRJLTkafp4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2° Separação da base de treinamento e criaçao do *input_values*\n","Resultados:\n","- Dicionario *dict_train* contendo a base de treinamento separado por estação. Nesta etapa, a base foi transformada em um np.array, tendo os campos *Est, Time, x, y, z, lat, lon e alt* removidos\n","- Lista *input_values* uma lista ordenanda por tp_est contendo todas as linhas da base de treinamento que possuiam todos os dados preenchidos\n","\n","OBS: Como foi decidido separar a base por estações, os valores de *x, y, z, lat, lon e alt* não são mais necessários, e por este motivo foram removidos da base"],"metadata":{"id":"mr2OAvdpbYKQ"}},{"cell_type":"code","source":["dict_train = {}\n","\n","df_train_grouped = df_raw_train.groupby(['Est'])\n","for est in df_train_grouped.groups.keys():\n","    group = df_train_grouped.get_group(est).copy()\n","    dict_train[est] = group.drop(['Est', 'time', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1).values.tolist()"],"metadata":{"id":"0Pewtu2pbtUn","executionInfo":{"status":"ok","timestamp":1696735813215,"user_tz":180,"elapsed":637,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["Construção da lista *input_values*"],"metadata":{"id":"BfK3K4sof7Dv"}},{"cell_type":"code","source":["df_train_no_na = df_raw_train.dropna()\n","\n","input_values = []\n","columns = list(df_train_no_na.head())\n","for row in df_train_no_na.iterrows():\n","    row_info = {}\n","    for col in columns:\n","        row_info[col] = row[1][col]\n","\n","    input_values.append(row_info)\n","\n","input_values = sorted(input_values, key=lambda d: d[\"Tp_est\"])"],"metadata":{"id":"j-zkxN5-f-ba","executionInfo":{"status":"ok","timestamp":1696735820487,"user_tz":180,"elapsed":7276,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":["### 3° KNN Imputation na base de treinamento\n","\n","Realização de um KNN imputation para cada estação em especifico\n","\n","Resultados:\n","- *dict_train* com todas as linhas com valores preenchidos\n"],"metadata":{"id":"0zLSAdVge6AK"}},{"cell_type":"code","source":["imputer = KNNImputer(n_neighbors=5)\n","\n","for est in dict_train:\n","    dict_train[est] = imputer.fit_transform(dict_train[est])"],"metadata":{"id":"ZbPe13luceKv","executionInfo":{"status":"ok","timestamp":1696735847085,"user_tz":180,"elapsed":22608,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":["### 4° Removendo outliers\n","\n","Verificação dos outliers e remoção deles para cada estação\n","\n","Resultados:\n","- Remoção dos dados com tp_est maiores que 12.4, pois representavam uma parte infima da base de dados\n"],"metadata":{"id":"Q137-sOgpAcY"}},{"cell_type":"code","source":["est_data = {}\n","for est in dict_train:\n","    data = { '0 - 2.4': 0, '2.5 - 7.4': 0, '7.5 - 12.4': 0, '12.5 - 17.4': 0, '17.5 - 22.4': 0, '22.5 - 27.4': 0, '27.5 - 32.4': 0,  '32.4 - 37.5': 0}\n","    for row in dict_train[est]:\n","        if float(row[-1]) < 2.4:\n","            data['0 - 2.4'] += 1\n","        elif float(row[-1]) < 7.4:\n","            data['2.5 - 7.4'] += 1\n","        elif float(row[-1]) < 12.4:\n","            data['7.5 - 12.4'] += 1\n","        elif float(row[-1]) < 17.4:\n","            data['12.5 - 17.4'] += 1\n","        elif float(row[-1]) < 22.4:\n","            data['17.5 - 22.4'] += 1\n","        elif float(row[-1]) < 27.4:\n","            data['22.5 - 27.4'] += 1\n","        elif float(row[-1]) < 32.4:\n","            data['27.5 - 32.4'] += 1\n","        else:\n","            data['32.4 - 37.5'] += 1\n","    est_data[est] = data\n","\n","est_data"],"metadata":{"id":"6eOzPWbvqnE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_dict_train = {}\n","for est in dict_train:\n","    indexes = []\n","    for index, row in enumerate(dict_train[est]):\n","        if row[-1] >= 12.4:\n","            indexes.append(index)\n","    temp = np.delete(dict_train[est], indexes, 0)\n","    new_dict_train[est] = temp\n","\n","dict_train = new_dict_train"],"metadata":{"id":"U6FJmBWzr__R","executionInfo":{"status":"ok","timestamp":1696735850364,"user_tz":180,"elapsed":2,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":["### (*) Oversampling?"],"metadata":{"id":"fbol-JFg88le"}},{"cell_type":"code","source":["columns = ['azimuth', 'range', 'UH', 'UV', 'DBZH', 'DBZV', 'KDP', 'ZDR', 'RHOHV', 'Tp_est']\n","\n","testes = {}\n","for est in dict_train:\n","    df = pd.DataFrame(data=dict_train[est], columns=columns)\n","    teste = smogn.smoter(data=df.reset_index(drop=True), y=\"Tp_est\", samp_method='balance')\n","    testes[est] = teste"],"metadata":{"id":"Y4_xi3vf9AjR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["teste2 = {}\n","for teste in testes:\n","    teste2[teste] = np.array(testes[teste].values.tolist())\n","\n","dict_train = teste2"],"metadata":{"id":"xsx9DWQAJO0J","executionInfo":{"status":"ok","timestamp":1696732755255,"user_tz":180,"elapsed":376,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["### 5° Preparação da base de validação\n","Realização do Data Imputation na base de validação.\n","\n","Resultados:\n","- Base de validação com todas as linhas com valores preenchidos (*df_validation*)\n","\n","OBS: Não foi utilizado o KNN Imputation pois os dados deste Data Imputation são oriundo da base de treinamento, e não da própia base de validação"],"metadata":{"id":"Eyvzohs5uoc1"}},{"cell_type":"code","source":["df_validation = df_raw_validation.copy()"],"metadata":{"id":"s8yORyXHci4G","executionInfo":{"status":"ok","timestamp":1696735157673,"user_tz":180,"elapsed":234,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":["Realizando o input na base de dados de validação"],"metadata":{"id":"4WNNEKQJcn0O"}},{"cell_type":"code","source":["def get_fields_to_input(row, columns):\n","    fields = []\n","    for col in columns:\n","        if str(row[col]) == 'nan':\n","            fields.append(col)\n","    return fields\n","\n","def get_data(tp_est, input_values):\n","    data = None\n","    min_distance = math.inf\n","    for value in input_values:\n","        distance = abs(tp_est - value[\"Tp_est\"])\n","        if distance < min_distance:\n","            min_distance = distance\n","            data = value\n","\n","    return data\n","\n","columns = list(df_validation.head())\n","for row in df_validation.iterrows():\n","\n","    fields_to_input = get_fields_to_input(row[1], columns)\n","    if len(fields_to_input) > 0:\n","        input_data = get_data(row[1][\"Tp_est\"], input_values)\n","        for field in fields_to_input:\n","            if str(row[1][field]) == 'nan':\n","                df_validation.loc[row[0], field] = input_data[col]"],"metadata":{"id":"ZtCQ7lVbq5LF","executionInfo":{"status":"ok","timestamp":1696735216745,"user_tz":180,"elapsed":58702,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":["### 6° Validaçao dos modelos de regressão\n","\n","Validação dos 4 modelos de regressão utilizados:\n","- Linear Regression\n","- Tree Regresion\n","- SVR\n","- KNN\n","\n","Com os resultados obtidos, uma nova clusterização da base de treinamento foi montada\n","\n","Resultados:\n","- Validação dos modelos para construção dos clusters finais de dados para o treinamento dos modelos finais\n"],"metadata":{"id":"MY94dFavy9Gp"}},{"cell_type":"code","source":["df_validation_for_train = df_validation.drop(['time','Est', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1)"],"metadata":{"id":"SGAGP6VuhXQx","executionInfo":{"status":"ok","timestamp":1696735858361,"user_tz":180,"elapsed":258,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":["Realizando o treinamento dos modelos e armazenando os valores das predições para calcular os erros e fazer comparações"],"metadata":{"id":"lpDKp1SstKQm"}},{"cell_type":"code","source":["def get_model(model):\n","    match model:\n","        case 'knn':\n","            return neighbors.KNeighborsRegressor(n_neighbors=100)\n","        case 'svr':\n","            return svm.SVR()\n","        case 'linear_regression':\n","            return linear_model.LinearRegression()\n","        case 'tree_regression':\n","            return tree.DecisionTreeRegressor()\n","\n","models = ['knn', 'svr', 'linear_regression', 'tree_regression']\n","est_preds = {}\n","\n","validate_list = np.array(df_validation_for_train.values.tolist())\n","x_validate = validate_list[:, :-1]\n","y_validate = validate_list[:, -1]\n","\n","for est in dict_train:\n","    train_list = dict_train[est]\n","    x_train = train_list[:, :-1]\n","    y_train = train_list[:, -1]\n","\n","    preds = {}\n","    for model_type in models:\n","        model = get_model(model_type)\n","        model.fit(x_train, y_train)\n","\n","        pred = model.predict(x_validate)\n","        preds[model_type] = pred\n","\n","    est_preds[est] = preds"],"metadata":{"id":"d4szK7eCzOph","executionInfo":{"status":"ok","timestamp":1696735924041,"user_tz":180,"elapsed":65296,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":["Construção de um dicionário armazenando os erros de predição para cada estação"],"metadata":{"id":"IyJPS90YtVhB"}},{"cell_type":"code","source":["errors = {}\n","for est in est_preds:\n","    est_errors = {}\n","    for model in est_preds[est]:\n","        mse = mean_squared_error(y_validate, est_preds[est][model])\n","        mae = mean_absolute_error(y_validate, est_preds[est][model])\n","        est_errors[model] = { 'mse': mse, 'mae': mae }\n","    errors[est] = est_errors"],"metadata":{"id":"d_adXBNg-e6j","executionInfo":{"status":"ok","timestamp":1696735924042,"user_tz":180,"elapsed":6,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":["Construindo uma tabela de comparação para tomar decisões sobre os resultados obtidos"],"metadata":{"id":"LKkTUVfvtbjL"}},{"cell_type":"code","source":["df_comparison = pd.DataFrame(columns=['Estação', 'Melhor Modelo MSE', 'MSE', 'Melhor Modelo MAE', 'MAE'])\n","\n","for est in errors:\n","    min_mse = None\n","    min_mse_value = math.inf\n","    min_mae = None\n","    min_mae_value = math.inf\n","\n","    for model in errors[est]:\n","        if errors[est][model]['mse'] < min_mse_value:\n","            min_mse = model\n","            min_mse_value = errors[est][model]['mse']\n","        if errors[est][model]['mae'] < min_mae_value:\n","            min_mae = model\n","            min_mae_value = errors[est][model]['mae']\n","    new_row = [est, min_mse, min_mse_value, min_mae, min_mae_value]\n","    df_comparison.loc[len(df_comparison)] = new_row\n","\n","df_comparison"],"metadata":{"id":"wZhCPHiIAoZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 7° Clusterização final da base de treinamento\n","\n","Com os resultados obtidos na validação, a base de treinamento foi separado em 2 clustes, um para treinar um KNN Regressor e o outro para treinar um Linear Regressor\n","\n","Resultados:\n","- Criação do dicionário *cluster_train* para o treinamento dos modelos finais"],"metadata":{"id":"Ep9NWKiqoQN0"}},{"cell_type":"code","source":["clusters = {\n","    'knn': ['Aguas_do_Vere', 'Altonia', 'Assis_Chateaubriand', 'Baixo_Iguacu', 'Bela_Vista_Jusante', 'Campo_Mourao', 'Cascavel', 'Coronel_Domingos_Soares',\n","     'Derivacao_do_Rio_Jordao', 'Foz_do_Iguacu_-_Itaipu', 'Laranjeiras_do_Sul', 'Loanda', 'Paranavai', 'Porto_Formosa', 'Porto_Santo_Antonio',\n","     'Reservatorio_Salto_Caxias', 'Salto_Caxias', 'Santa_Helena', 'Solais_Novo', 'Toledo', 'Umuarama'],\n","    'linear': ['Boa_Vista_da_Aparecida', 'Guaira', 'Palotina', 'Pato_Branco', 'Segredo', 'Ubirata']\n","}\n","cluster_train = {}\n","\n","for cluster in clusters:\n","    group = dict_train[clusters[cluster][0]]\n","    for index in range(1, len(clusters[cluster])):\n","        group = np.concatenate((group, dict_train[clusters[cluster][index]]), axis=0)\n","    cluster_train[cluster] = group"],"metadata":{"id":"6RbrmyyVoeK_","executionInfo":{"status":"ok","timestamp":1696727899395,"user_tz":180,"elapsed":229,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### 8° validação do valor do k para o KNN Regressor\n","\n","Resultados:\n","- O valor otimo para k"],"metadata":{"id":"lG5A9B-0Vp54"}},{"cell_type":"code","source":["train_list = cluster_train['knn']\n","x = train_list[:, :-1]\n","y = train_list[:, -1]\n","\n","validate_list = np.array(df_validation_for_train.values.tolist())\n","x_validate = validate_list[:, :-1]\n","y_validate = validate_list[:, -1]\n","\n","min_mse = math.inf\n","mses = []\n","for k in range(1, 300):\n","    model = neighbors.KNeighborsRegressor(n_neighbors=k)\n","    model.fit(x, y)\n","    pred = model.predict(x_validate)\n","    mse = mean_squared_error(y_validate, pred)\n","    if mse < min_mse:\n","        min_mse = mse\n","\n","    mses.append(mse)"],"metadata":{"id":"o5aDaP1QVw14","executionInfo":{"status":"ok","timestamp":1696740333733,"user_tz":180,"elapsed":244933,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":["Gráfico da medida MSE de erro para cada K"],"metadata":{"id":"ERbBW5siicDE"}},{"cell_type":"code","source":["print(f'mse: {min_mse} - {mses.index(min_mse) + 1}')\n","\n","x = range(1, len(mses) + 1)\n","y = mses\n","\n","plt.title('Validação do K')\n","plt.plot(x, y)\n","plt.show()"],"metadata":{"id":"sMqxWZpuf3zE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 9° Preparação da base de teste\n","\n","Realização do Data Imputation na base de teste\n","\n","Resultados:\n","- Base de teste com todas as linhas com valores preenchidos (*df_test*)\n","\n","OBS: Não foi utilizado o KNN Imputation pois os dados deste Data Imputation são oriundo da base de treinamento, e não da própia base de validação\n"],"metadata":{"id":"ZSz9lc8Ori2h"}},{"cell_type":"code","source":["df_test = df_raw_test.drop(['time','Est', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1)"],"metadata":{"id":"2s4w96our7nd","executionInfo":{"status":"ok","timestamp":1696727908398,"user_tz":180,"elapsed":247,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Realizando o input na base de teste"],"metadata":{"id":"UlbZaBaGsBtC"}},{"cell_type":"code","source":["def get_fields_to_input(row, columns):\n","    fields = []\n","    for col in columns:\n","        if str(row[col]) == 'nan':\n","            fields.append(col)\n","    return fields\n","\n","def get_data(tp_est, input_values):\n","    data = None\n","    min_distance = math.inf\n","    for value in input_values:\n","        distance = abs(tp_est - value[\"Tp_est\"])\n","        if distance < min_distance:\n","            min_distance = distance\n","            data = value\n","\n","    return data\n","\n","columns = list(df_test.head())\n","for row in df_test.iterrows():\n","\n","    fields_to_input = get_fields_to_input(row[1], columns)\n","    if len(fields_to_input) > 0:\n","        input_data = get_data(row[1][\"Tp_est\"], input_values)\n","        for field in fields_to_input:\n","            if str(row[1][field]) == 'nan':\n","                df_test.loc[row[0], field] = input_data[col]"],"metadata":{"id":"5UieOuQXsBdr","executionInfo":{"status":"ok","timestamp":1696728225745,"user_tz":180,"elapsed":317106,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### 10° Treinamento dos modelos finais\n","\n","Resultado:\n","- 1 Modelo KNN Regressor\n","- 1 Modelo Linear Regressor"],"metadata":{"id":"rd0VSwQ-tjHI"}},{"cell_type":"code","source":["knn = neighbors.KNeighborsRegressor(n_neighbors=224)\n","linear = linear_model.LinearRegression()\n","\n","knn_train = cluster_train['knn']\n","linear_train = cluster_train['linear']\n","\n","x_knn = knn_train[:, :-1]\n","y_knn = knn_train[:, -1]\n","\n","x_linear = linear_train[:, :-1]\n","y_linear = linear_train[:, -1]\n","\n","knn.fit(x_knn, y_knn)\n","linear.fit(x_linear, y_linear)"],"metadata":{"id":"HvGKie2utsaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 11° Predições e Resultados\n","\n","Realização das predições finais para o modelo\n","\n","Resultados:\n","- Metricas de erro MSE e MAE\n","- Gráfico de Dispersão\n"],"metadata":{"id":"dyOvRuzBuikG"}},{"cell_type":"code","source":["test_list = np.array(df_test.values.tolist())\n","x_test = test_list[:, :-1]\n","y_test = test_list[:, -1]\n","\n","knn_pred = knn.predict(x_test)\n","linear_pred = linear.predict(x_test)\n","\n","final_pred = [a + b for a,b in zip(knn_pred, linear_pred)]\n","final_pred = [x / 2 for x in final_pred]"],"metadata":{"id":"Mj_EMaybusSH","executionInfo":{"status":"ok","timestamp":1696738850223,"user_tz":180,"elapsed":4541,"user":{"displayName":"Paulo Mateus Luza Alves","userId":"12822114180034320779"}}},"execution_count":121,"outputs":[]},{"cell_type":"markdown","source":["Cálculo e print das medidas de erro"],"metadata":{"id":"r-xWSUNd8t1l"}},{"cell_type":"code","source":["mse = mean_squared_error(y_test, final_pred)\n","mae = mean_absolute_error(y_test, final_pred)\n","\n","print(f'mse: {mse} - mae: {mae}')"],"metadata":{"id":"p58loNl1vNp9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Construção do gráfico de dispersão"],"metadata":{"id":"kXMVAV-J8xY_"}},{"cell_type":"code","source":["x = y_test\n","y = final_pred\n","\n","plt.title('Gráfico de Dispersão')\n","plt.scatter(x, y)\n","plt.show()"],"metadata":{"id":"w3aTkr7IwywB"},"execution_count":null,"outputs":[]}]}