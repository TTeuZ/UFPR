{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kjzztfGwe1XX"},"outputs":[],"source":["import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.impute import KNNImputer\n","from sklearn import neighbors\n","from sklearn import linear_model\n","from sklearn import svm\n","from sklearn import tree\n","from sklearn.metrics import mean_squared_error, mean_absolute_error"]},{"cell_type":"markdown","metadata":{"id":"Dp3ndF8DfZRl"},"source":["### 1° Leitura e tratamento inicial dos dados\n","\n","Lendo a CSV e removendo todos os dados com valores de Tp_est iguais a zero. Além disso, foi realizado o tratamento inicial e construção das 3 bases de dados usados no algoritmo\n","\n","Resultados:\n","- Base de dados raw para treinamento (*df_raw_train*)\n","- Base de dados raw para validação (*df_raw_validation*)\n","- Base de dados raw para teste (*df_raw_test*)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"apl-nNRqfdxS"},"outputs":[],"source":["df_raw_data = pd.read_csv('Dados_Radar_Estacao_Completo_2018_2022.csv')\n","df_raw_data.drop(df_raw_data[df_raw_data['Tp_est'] == 0.0].index, inplace=True);"]},{"cell_type":"markdown","metadata":{"id":"ZfVDhdkUffjS"},"source":["Remoção de colunas da base geral (2018 a 2022). A colunas removidas foram:\n","- Unnamed: 0 pois é a coluna de ids\n","- latitude e longitude pois possuem a mesma informação que as colunas lat e lon;\n","- distancia pois não agrega valor ao modelo.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDVwGtoxXAJ-"},"outputs":[],"source":["df_raw_data.drop(['Unnamed: 0', 'latitude', 'longitude', 'distancia'], axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"niHUe8qRfkJ1"},"source":["Separando o raw data entre treinamento e teste. Anos de 2018 a 2021 para treinamento e 2022 para teste.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpE1520yfk37"},"outputs":[],"source":["raw_train_test_group = df_raw_data.groupby(df_raw_data['time'].str.contains('2022'))\n","\n","df_raw_train = raw_train_test_group.get_group(False).copy()\n","df_raw_test = raw_train_test_group.get_group(True).copy()"]},{"cell_type":"markdown","metadata":{"id":"GoFReL0bEj1I"},"source":["Separando os dados de treinamento, selecionando uma porção dos dados para validação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bcSHW_v-foR1"},"outputs":[],"source":["dates = ['2018-01', '2018-02']\n","\n","raw_train_validation_group = df_raw_train.groupby(df_raw_train['time'].str.contains('|'.join(dates)))\n","df_raw_train = raw_train_validation_group.get_group(False).copy()\n","df_raw_validation = raw_train_validation_group.get_group(True).copy()\n"]},{"cell_type":"markdown","metadata":{"id":"x2L_kDfHfqD-"},"source":["Remoção das colunas elevation e sweep pois não possuiam valor agregado na base\n","\n","Para verificar que as colunas elevation e sweep não possuiam valor agregado, foi utilizado a função describe do pandas. Com esta função, foi possível verificar que ambas possuiam média, minimo e maximo identicos, além de um desvio padrão igual a 0, ou seja, todas as linhas possuiam o mesmo valor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pRJLTkafp4_"},"outputs":[],"source":["print(df_raw_train.describe()['elevation'], end=\"\\n\\n\")\n","print(df_raw_train.describe()['sweep'])\n","\n","df_raw_train.drop(['elevation', 'sweep'], axis=1, inplace=True)\n","df_raw_validation.drop(['elevation', 'sweep'], axis=1, inplace=True)\n","df_raw_test.drop(['elevation', 'sweep'], axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"mr2OAvdpbYKQ"},"source":["### 2° Separação da base de treinamento e criaçao do *input_values*\n","Resultados:\n","- Dicionario *dict_train* contendo a base de treinamento separado por estação. Nesta etapa, a base foi transformada em um np.array, tendo os campos *Est, Time, x, y, z, lat, lon e alt* removidos\n","- Lista *input_values* uma lista ordenanda por tp_est contendo todas as linhas da base de treinamento que possuiam todos os dados preenchidos\n","\n","OBS: Como foi decidido separar a base por estações, os valores de *x, y, z, lat, lon e alt* não são mais necessários, e por este motivo foram removidos da base"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Pewtu2pbtUn"},"outputs":[],"source":["dict_train = {}\n","\n","df_train_grouped = df_raw_train.groupby(['Est'])\n","for est in df_train_grouped.groups.keys():\n","    group = df_train_grouped.get_group(est).copy()\n","    dict_train[est] = group.drop(['Est', 'time', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1).values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"BfK3K4sof7Dv"},"source":["Construção da lista *input_values*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-zkxN5-f-ba"},"outputs":[],"source":["df_train_no_na = df_raw_train.dropna()\n","\n","input_values = []\n","columns = list(df_train_no_na.head())\n","for row in df_train_no_na.iterrows():\n","    row_info = {}\n","    for col in columns:\n","        row_info[col] = row[1][col]\n","\n","    input_values.append(row_info)\n","\n","input_values = sorted(input_values, key=lambda d: d[\"Tp_est\"])"]},{"cell_type":"markdown","metadata":{"id":"0zLSAdVge6AK"},"source":["### 3° KNN Imputation na base de treinamento\n","\n","Realização de um KNN imputation para cada estação em especifico\n","\n","Resultados:\n","- *dict_train* com todas as linhas com valores preenchidos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbPe13luceKv"},"outputs":[],"source":["imputer = KNNImputer(n_neighbors=5)\n","\n","for est in dict_train:\n","    dict_train[est] = imputer.fit_transform(dict_train[est])"]},{"cell_type":"markdown","metadata":{"id":"Q137-sOgpAcY"},"source":["### 4° Removendo outliers\n","\n","Verificação dos outliers e remoção deles para cada estação\n","\n","Resultados:\n","- Remoção dos dados com tp_est maiores que 12.4, pois representavam uma parte infima da base de dados\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eOzPWbvqnE9"},"outputs":[],"source":["est_data = {}\n","for est in dict_train:\n","    data = { '0 - 2.4': 0, '2.5 - 7.4': 0, '7.5 - 12.4': 0, '12.5 - 17.4': 0, '17.5 - 22.4': 0, '22.5 - 27.4': 0, '27.5 - 32.4': 0,  '32.4 - 37.5': 0}\n","    for row in dict_train[est]:\n","        if float(row[-1]) < 2.4:\n","            data['0 - 2.4'] += 1\n","        elif float(row[-1]) < 7.4:\n","            data['2.5 - 7.4'] += 1\n","        elif float(row[-1]) < 12.4:\n","            data['7.5 - 12.4'] += 1\n","        elif float(row[-1]) < 17.4:\n","            data['12.5 - 17.4'] += 1\n","        elif float(row[-1]) < 22.4:\n","            data['17.5 - 22.4'] += 1\n","        elif float(row[-1]) < 27.4:\n","            data['22.5 - 27.4'] += 1\n","        elif float(row[-1]) < 32.4:\n","            data['27.5 - 32.4'] += 1\n","        else:\n","            data['32.4 - 37.5'] += 1\n","    est_data[est] = data\n","\n","est_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6FJmBWzr__R"},"outputs":[],"source":["new_dict_train = {}\n","for est in dict_train:\n","    indexes = []\n","    for index, row in enumerate(dict_train[est]):\n","        if row[-1] >= 12.4:\n","            indexes.append(index)\n","    temp = np.delete(dict_train[est], indexes, 0)\n","    new_dict_train[est] = temp\n","\n","dict_train = new_dict_train"]},{"cell_type":"markdown","metadata":{"id":"Eyvzohs5uoc1"},"source":["### 5° Preparação da base de validação\n","Realização do Data Imputation na base de validação.\n","\n","Resultados:\n","- Base de validação com todas as linhas com valores preenchidos (*df_validation*)\n","\n","OBS: Não foi utilizado o KNN Imputation pois os dados deste Data Imputation são oriundo da base de treinamento, e não da própia base de validação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8yORyXHci4G"},"outputs":[],"source":["df_validation = df_raw_validation.copy()"]},{"cell_type":"markdown","metadata":{"id":"4WNNEKQJcn0O"},"source":["Realizando o input na base de dados de validação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtCQ7lVbq5LF"},"outputs":[],"source":["def get_fields_to_input(row, columns):\n","    fields = []\n","    for col in columns:\n","        if str(row[col]) == 'nan':\n","            fields.append(col)\n","    return fields\n","\n","def get_data(tp_est, input_values):\n","    data = None\n","    min_distance = math.inf\n","    for value in input_values:\n","        distance = abs(tp_est - value[\"Tp_est\"])\n","        if distance < min_distance:\n","            min_distance = distance\n","            data = value\n","\n","    return data\n","\n","columns = list(df_validation.head())\n","for row in df_validation.iterrows():\n","\n","    fields_to_input = get_fields_to_input(row[1], columns)\n","    if len(fields_to_input) > 0:\n","        input_data = get_data(row[1][\"Tp_est\"], input_values)\n","        for field in fields_to_input:\n","            if str(row[1][field]) == 'nan':\n","                df_validation.loc[row[0], field] = input_data[col]"]},{"cell_type":"markdown","metadata":{"id":"MY94dFavy9Gp"},"source":["### 6° Validaçao dos modelos de regressão\n","\n","Validação dos 4 modelos de regressão utilizados:\n","- Linear Regression\n","- Tree Regresion\n","- SVR\n","- KNN\n","\n","Com os resultados obtidos, uma nova clusterização da base de treinamento foi montada\n","\n","Resultados:\n","- Validação dos modelos para construção dos clusters finais de dados para o treinamento dos modelos finais\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SGAGP6VuhXQx"},"outputs":[],"source":["df_validation_for_train = df_validation.drop(['time','Est', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"lpDKp1SstKQm"},"source":["Realizando o treinamento dos modelos e armazenando os valores das predições para calcular os erros e fazer comparações"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d4szK7eCzOph"},"outputs":[],"source":["def get_model(model):\n","    match model:\n","        case 'knn':\n","            return neighbors.KNeighborsRegressor(n_neighbors=100)\n","        case 'svr':\n","            return svm.SVR()\n","        case 'linear_regression':\n","            return linear_model.LinearRegression()\n","        case 'tree_regression':\n","            return tree.DecisionTreeRegressor()\n","\n","models = ['knn', 'svr', 'linear_regression', 'tree_regression']\n","est_preds = {}\n","\n","validate_list = np.array(df_validation_for_train.values.tolist())\n","x_validate = validate_list[:, :-1]\n","y_validate = validate_list[:, -1]\n","\n","for est in dict_train:\n","    train_list = dict_train[est]\n","    x_train = train_list[:, :-1]\n","    y_train = train_list[:, -1]\n","\n","    preds = {}\n","    for model_type in models:\n","        model = get_model(model_type)\n","        model.fit(x_train, y_train)\n","\n","        pred = model.predict(x_validate)\n","        preds[model_type] = pred\n","\n","    est_preds[est] = preds"]},{"cell_type":"markdown","metadata":{"id":"IyJPS90YtVhB"},"source":["Construção de um dicionário armazenando os erros de predição para cada estação"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_adXBNg-e6j"},"outputs":[],"source":["errors = {}\n","for est in est_preds:\n","    est_errors = {}\n","    for model in est_preds[est]:\n","        mse = mean_squared_error(y_validate, est_preds[est][model])\n","        mae = mean_absolute_error(y_validate, est_preds[est][model])\n","        est_errors[model] = { 'mse': mse, 'mae': mae }\n","    errors[est] = est_errors"]},{"cell_type":"markdown","metadata":{"id":"LKkTUVfvtbjL"},"source":["Construindo uma tabela de comparação para tomar decisões sobre os resultados obtidos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZhCPHiIAoZb"},"outputs":[],"source":["df_comparison = pd.DataFrame(columns=['Estação', 'Melhor Modelo MSE', 'MSE', 'Melhor Modelo MAE', 'MAE'])\n","\n","for est in errors:\n","    min_mse = None\n","    min_mse_value = math.inf\n","    min_mae = None\n","    min_mae_value = math.inf\n","\n","    for model in errors[est]:\n","        if errors[est][model]['mse'] < min_mse_value:\n","            min_mse = model\n","            min_mse_value = errors[est][model]['mse']\n","        if errors[est][model]['mae'] < min_mae_value:\n","            min_mae = model\n","            min_mae_value = errors[est][model]['mae']\n","    new_row = [est, min_mse, min_mse_value, min_mae, min_mae_value]\n","    df_comparison.loc[len(df_comparison)] = new_row\n","\n","df_comparison"]},{"cell_type":"markdown","metadata":{"id":"Ep9NWKiqoQN0"},"source":["### 7° Clusterização final da base de treinamento\n","\n","Com os resultados obtidos na validação, a base de treinamento foi separado em 2 clustes, um para treinar um KNN Regressor e o outro para treinar um Linear Regressor\n","\n","Resultados:\n","- Criação do dicionário *cluster_train* para o treinamento dos modelos finais"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RbrmyyVoeK_"},"outputs":[],"source":["# clusters = {\n","#     'knn': ['Aguas_do_Vere', 'Altonia', 'Assis_Chateaubriand', 'Baixo_Iguacu', 'Bela_Vista_Jusante', 'Campo_Mourao', 'Cascavel', 'Coronel_Domingos_Soares',\n","#      'Derivacao_do_Rio_Jordao', 'Foz_do_Iguacu_-_Itaipu', 'Laranjeiras_do_Sul', 'Loanda', 'Paranavai', 'Porto_Formosa', 'Porto_Santo_Antonio',\n","#      'Reservatorio_Salto_Caxias', 'Salto_Caxias', 'Santa_Helena', 'Solais_Novo', 'Toledo', 'Umuarama'],\n","#     'linear': ['Boa_Vista_da_Aparecida', 'Guaira', 'Palotina', 'Pato_Branco', 'Segredo', 'Ubirata']\n","# }\n","clusters = {\n","    'knn': ['Aguas_do_Vere', 'Altonia', 'Assis_Chateaubriand', 'Bela_Vista_Jusante', 'Cascavel', 'Derivacao_do_Rio_Jordao', 'Foz_do_Iguacu_-_Itaipu',\n","            'Laranjeiras_do_Sul', 'Loanda', 'Palotina', 'Paranavai', 'Pato_Branco', 'Reservatorio_Salto_Caxias', 'Salto_Caxias', 'Santa_Helena',\n","            'Segredo', 'Solais_Novo', 'Toledo', 'Ubirata', 'Umuarama'],\n","    'linear': ['Baixo_Iguacu', 'Boa_Vista_da_Aparecida', 'Campo_Mourao', 'Coronel_Domingos_Soares', 'Guaira','Porto_Formosa', 'Porto_Santo_Antonio']\n","}\n","cluster_train = {}\n","\n","for cluster in clusters:\n","    group = dict_train[clusters[cluster][0]]\n","    for index in range(1, len(clusters[cluster])):\n","        group = np.concatenate((group, dict_train[clusters[cluster][index]]), axis=0)\n","    cluster_train[cluster] = group"]},{"cell_type":"markdown","metadata":{"id":"lG5A9B-0Vp54"},"source":["### 8° validação do valor do k para o KNN Regressor\n","\n","Resultados:\n","- O valor otimo para k"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5aDaP1QVw14"},"outputs":[],"source":["train_list = cluster_train['knn']\n","x = train_list[:, :-1]\n","y = train_list[:, -1]\n","\n","validate_list = np.array(df_validation_for_train.values.tolist())\n","x_validate = validate_list[:, :-1]\n","y_validate = validate_list[:, -1]\n","\n","min_mse = math.inf\n","mses = []\n","for k in range(1, 300):\n","    model = neighbors.KNeighborsRegressor(n_neighbors=k)\n","    model.fit(x, y)\n","    pred = model.predict(x_validate)\n","    mse = mean_squared_error(y_validate, pred)\n","    if mse < min_mse:\n","        min_mse = mse\n","\n","    mses.append(mse)"]},{"cell_type":"markdown","metadata":{"id":"ERbBW5siicDE"},"source":["Gráfico da medida MSE de erro para cada K"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sMqxWZpuf3zE"},"outputs":[],"source":["print(f'mse: {min_mse} - {mses.index(min_mse) + 1}')\n","\n","x = range(1, len(mses) + 1)\n","y = mses\n","\n","plt.title('Validação do K')\n","plt.plot(x, y)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZSz9lc8Ori2h"},"source":["### 9° Preparação da base de teste\n","\n","Realização do Data Imputation na base de teste\n","\n","Resultados:\n","- Base de teste com todas as linhas com valores preenchidos (*df_test*)\n","\n","OBS: Não foi utilizado o KNN Imputation pois os dados deste Data Imputation são oriundo da base de treinamento, e não da própia base de validação\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2s4w96our7nd"},"outputs":[],"source":["df_test = df_raw_test.drop(['time','Est', 'x', 'y', 'z', 'lat', 'lon', 'alt'], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"UlbZaBaGsBtC"},"source":["Realizando o input na base de teste"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5UieOuQXsBdr"},"outputs":[],"source":["def get_fields_to_input(row, columns):\n","    fields = []\n","    for col in columns:\n","        if str(row[col]) == 'nan':\n","            fields.append(col)\n","    return fields\n","\n","def get_data(tp_est, input_values):\n","    data = None\n","    min_distance = math.inf\n","    for value in input_values:\n","        distance = abs(tp_est - value[\"Tp_est\"])\n","        if distance < min_distance:\n","            min_distance = distance\n","            data = value\n","\n","    return data\n","\n","columns = list(df_test.head())\n","for row in df_test.iterrows():\n","\n","    fields_to_input = get_fields_to_input(row[1], columns)\n","    if len(fields_to_input) > 0:\n","        input_data = get_data(row[1][\"Tp_est\"], input_values)\n","        for field in fields_to_input:\n","            if str(row[1][field]) == 'nan':\n","                df_test.loc[row[0], field] = input_data[col]"]},{"cell_type":"markdown","metadata":{"id":"rd0VSwQ-tjHI"},"source":["### 10° Treinamento dos modelos finais\n","\n","Resultado:\n","- 1 Modelo KNN Regressor\n","- 1 Modelo Linear Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvGKie2utsaU"},"outputs":[],"source":["knn = neighbors.KNeighborsRegressor(n_neighbors=82)\n","linear = linear_model.LinearRegression()\n","\n","knn_train = cluster_train['knn']\n","linear_train = cluster_train['linear']\n","\n","x_knn = knn_train[:, :-1]\n","y_knn = knn_train[:, -1]\n","\n","x_linear = linear_train[:, :-1]\n","y_linear = linear_train[:, -1]\n","\n","knn.fit(x_knn, y_knn)\n","linear.fit(x_linear, y_linear)"]},{"cell_type":"markdown","metadata":{"id":"dyOvRuzBuikG"},"source":["### 11° Predições e Resultados\n","\n","Realização das predições finais para o modelo\n","\n","Resultados:\n","- Metricas de erro MSE e MAE\n","- Gráfico de Dispersão\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mj_EMaybusSH"},"outputs":[],"source":["test_list = np.array(df_test.values.tolist())\n","x_test = test_list[:, :-1]\n","y_test = test_list[:, -1]\n","\n","knn_pred = knn.predict(x_test)\n","linear_pred = linear.predict(x_test)\n","\n","final_pred = [a + b for a,b in zip(knn_pred, linear_pred)]\n","final_pred = [x / 2 for x in final_pred]"]},{"cell_type":"markdown","metadata":{"id":"r-xWSUNd8t1l"},"source":["Cálculo e print das medidas de erro"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p58loNl1vNp9"},"outputs":[],"source":["mse = mean_squared_error(y_test, final_pred)\n","mae = mean_absolute_error(y_test, final_pred)\n","\n","print(f'mse: {mse} - mae: {mae}')"]},{"cell_type":"markdown","metadata":{"id":"kXMVAV-J8xY_"},"source":["Construção do gráfico de dispersão"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3aTkr7IwywB"},"outputs":[],"source":["x = y_test\n","y = final_pred\n","\n","plt.xlabel('Valores da predição')\n","plt.ylabel('Valores de Tp_est')\n","plt.title('Gráfico de Dispersão')\n","plt.scatter(x, y)\n","plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNhpMquzTFhM1vL4GUkH3Kt","collapsed_sections":["Dp3ndF8DfZRl","mr2OAvdpbYKQ","0zLSAdVge6AK","Q137-sOgpAcY","Eyvzohs5uoc1","MY94dFavy9Gp","Ep9NWKiqoQN0","lG5A9B-0Vp54","ZSz9lc8Ori2h","rd0VSwQ-tjHI","dyOvRuzBuikG"],"mount_file_id":"1NRRo5SnMvjC5WojFrVo94q_dU7U3KS4d","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
